# ğŸ™ï¸ Speech Emotion Recognition (SER) using Machine Learning

This project is a complete pipeline for recognizing emotions from speech audio data using machine learning techniques. The system extracts features from `.wav` files (like MFCCs, Chroma, and Mel spectrograms), trains a classifier (e.g., Random Forest or XGBoost), and predicts the emotion conveyed in speech.

## ğŸ“Š Demo
> ğŸ§ª Streamlit app coming soon...

## ğŸš€ Features
- Audio feature extraction using Librosa (MFCC, Chroma, Spectral Contrast, Tonnetz, Log-Mel)
- Handles imbalanced classes using oversampling
- Trains classification models (Random Forest, XGBoost, etc.)
- Provides model evaluation (confusion matrix, F1-score)
- Supports testing new audio samples via `test.py` script
- Interactive UI planned with Streamlit

## ğŸ—‚ï¸ Project Structure
```
ğŸ“ MARS project/
â”œâ”€â”€ ğŸ““ speech_emotio_recognition.ipynb  # Main training and evaluation pipeline
â”œâ”€â”€ ğŸ test.py                          # Script to test model with new data
â”œâ”€â”€ ğŸ“ Audio_Song_Actors_*              # Dataset (e.g., RAVDESS)
â”œâ”€â”€ ğŸ“ models/                          # Saved trained models
â”œâ”€â”€ ğŸ“ features/                        # Extracted features (optional cache)
â””â”€â”€ README.md                           # Project overview
```

## ğŸ§° Tech Stack
- Python 3.10+
- Libraries:
  - `librosa`, `numpy`, `pandas`, `matplotlib`, `seaborn`
  - `scikit-learn`, `xgboost`
  - `streamlit` (for UI)
- Audio Dataset: [RAVDESS](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)

## âš™ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/speech-emotion-recognition.git
   cd speech-emotion-recognition
   ```

2. **Create and activate virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Download and place the dataset**
   - Download RAVDESS or your dataset.
   - Place it in a folder like `Audio_Song_Actors_01-24`.

## ğŸ§ª Usage

### ğŸ§  Train the Model
Run the notebook to extract features, train the model, and evaluate performance:
```bash
jupyter notebook speech_emotio_recognition.ipynb
```

### ğŸ” Test with New Audio
```bash
python test.py
```
Make sure your test `.wav` file path is correctly specified in `test.py`.

### ğŸŒ (Optional) Run the Streamlit App
```bash
streamlit run app.py
```

## ğŸ“ˆ Evaluation Criteria
- Confusion matrix
- Accuracy > 80%
- F1-score > 80% per class

## ğŸ“Œ To-Do
- [x] Basic feature extraction
- [x] Classifier training
- [x] Evaluation metrics
- [ ] Save/load model
- [ ] Streamlit Web UI
- [ ] Hyperparameter tuning

## âœï¸ Authors
- Vivek Anningi

## ğŸ“„ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
